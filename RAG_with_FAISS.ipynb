{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Code Generation System with FAISS\n",
    "\n",
    "This notebook implements a complete RAG (Retrieval-Augmented Generation) system for code generation using:\n",
    "- **HumanEval Dataset**: For code examples\n",
    "- **Sentence Transformers**: For embeddings\n",
    "- **FAISS**: For vector similarity search\n",
    "- **OpenRouter API**: For code generation with open-source LLMs\n",
    "\n",
    "## Table of Contents\n",
    "1. Installation\n",
    "2. Dataset Loading\n",
    "3. Embedding Creation\n",
    "4. Vector Index Building\n",
    "5. Code Generation\n",
    "6. Examples & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets sentence-transformers faiss-cpu openai python-dotenv torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\NLP Cellula\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup API Key\n",
    "\n",
    "Get your OpenRouter API key from: https://openrouter.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your OpenRouter API key\n",
    "OPENROUTER_API_KEY = getpass(\"Enter your OpenRouter API key: \")\n",
    "\n",
    "# Or set it directly \n",
    "# OPENROUTER_API_KEY = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Functions\n",
    "\n",
    "Load and process the HumanEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_humaneval_dataset():\n",
    "    \"\"\"Load and process the HumanEval dataset.\"\"\"\n",
    "    print(\"Loading HumanEval dataset...\")\n",
    "    dataset = load_dataset(\"openai/openai_humaneval\", split=\"test\")\n",
    "    \n",
    "    examples = []\n",
    "    for item in dataset:\n",
    "        examples.append({\n",
    "            'task_id': item['task_id'],\n",
    "            'prompt': item['prompt'],\n",
    "            'canonical_solution': item['canonical_solution'],\n",
    "            'entry_point': item['entry_point']\n",
    "        })\n",
    "    \n",
    "    print(f\"✓ Loaded {len(examples)} examples\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "def extract_prompts(examples):\n",
    "    \"\"\"Extract all prompts from examples.\"\"\"\n",
    "    return [ex['prompt'] for ex in examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model_name):\n",
    "    \"\"\"Create embeddings for a list of texts using a specified model.\"\"\"\n",
    "    \n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    print(f\"Creating embeddings for {len(texts)} texts...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    embeddings_array = np.array(embeddings).astype('float32')\n",
    "    \n",
    "    print(f\"✓ Created embeddings with shape: {embeddings_array.shape}\")\n",
    "    return model, embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FAISS Index Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index_normalized(embeddings, doc_ids=None):\n",
    "    \n",
    "    print(\"Building normalized FAISS index with Inner Product...\")\n",
    "    \n",
    "    # Get dimension\n",
    "    dim = embeddings.shape[1]\n",
    "    \n",
    "    # Normalize embeddings to unit length (L2 normalization)\n",
    "    # This makes Inner Product equivalent to Cosine Similarity\n",
    "    norm_embeddings = embeddings.copy()\n",
    "    faiss.normalize_L2(norm_embeddings)\n",
    "    print(f\"✓ Normalized {len(norm_embeddings)} vectors\")\n",
    "    \n",
    "    # Create IDs if not provided\n",
    "    if doc_ids is None:\n",
    "        doc_ids = np.arange(len(embeddings)).astype('int64')\n",
    "    else:\n",
    "        doc_ids = np.array(doc_ids).astype('int64')\n",
    "    \n",
    "    # Create Inner Product index (faster and more accurate for normalized vectors)\n",
    "    base_index = faiss.IndexFlatIP(dim)\n",
    "    \n",
    "    # Wrap with IndexIDMap to maintain document IDs\n",
    "    faiss_index = faiss.IndexIDMap(base_index)\n",
    "    \n",
    "    # Add normalized vectors with IDs\n",
    "    faiss_index.add_with_ids(norm_embeddings, doc_ids)\n",
    "    \n",
    "    print(f\"✓ FAISS index built with {faiss_index.ntotal} vectors\")\n",
    "    print(f\"  Using: IndexIDMap(IndexFlatIP) for cosine similarity\")\n",
    "    \n",
    "    return faiss_index\n",
    "\n",
    "\n",
    "def search_similar(query, embedding_model, faiss_index, k=3):\n",
    "    # Encode query\n",
    "    query_embedding = embedding_model.encode([query]).astype('float32')\n",
    "    \n",
    "    # Normalize query vector\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    # Search (returns similarity scores, not distances)\n",
    "    similarities, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    return similarities[0], indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(examples):\n",
    "    \"\"\"Build context string from retrieved examples.\"\"\"\n",
    "    context_parts = []\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        context_parts.append(f\"Example {i}:\")\n",
    "        context_parts.append(f\"Task: {ex['prompt'].strip()}\")\n",
    "        context_parts.append(f\"Solution:\\n{ex['canonical_solution'].strip()}\")\n",
    "        context_parts.append(\"\")\n",
    "    return \"\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "def create_prompt(task_description, context):\n",
    "    \"\"\"Create the full prompt for code generation.\"\"\"\n",
    "    return f\"\"\"Based on the following examples of Python coding tasks and solutions, generate a complete function for the new task.\n",
    "\n",
    "{context}\n",
    "\n",
    "New Task:\n",
    "{task_description}\n",
    "\n",
    "Generate a complete, working Python function that solves this task. Include the function signature and implementation. Only return the code, no explanations.\"\"\"\n",
    "\n",
    "\n",
    "def extract_code(response):\n",
    "    \"\"\"Extract code from the LLM response.\"\"\"\n",
    "    if \"```python\" in response:\n",
    "        start = response.find(\"```python\") + len(\"```python\")\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    elif \"```\" in response:\n",
    "        start = response.find(\"```\") + 3\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def generate_code(task_description, retrieved_examples, api_key, \n",
    "                 model, max_tokens=500, temperature=0.2):\n",
    "    \"\"\"Generate code using OpenRouter API.\"\"\"\n",
    "    \n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    context = build_context(retrieved_examples)\n",
    "    prompt = create_prompt(task_description, context)\n",
    "    \n",
    "    print(\" Generating code...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert Python programmer. Generate clean, efficient, and well-documented code.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    generated_code = response.choices[0].message.content\n",
    "    return extract_code(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline(api_key, embedding_model_name):\n",
    "    print(\"=\"*80)\n",
    "    print(\"Setting up RAG Pipeline with Normalized FAISS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load dataset\n",
    "    examples = load_humaneval_dataset()\n",
    "    \n",
    "    # Create embeddings\n",
    "    prompts = extract_prompts(examples)\n",
    "    embedding_model, embeddings = create_embeddings(prompts, embedding_model_name)\n",
    "    \n",
    "    # Build normalized FAISS index with Inner Product\n",
    "    index = build_faiss_index_normalized(embeddings)\n",
    "    \n",
    "    print(\"\\n ✓ Pipeline setup complete!\\n\")\n",
    "    \n",
    "    return {\n",
    "        'examples': examples,\n",
    "        'embedding_model': embedding_model,\n",
    "        'faiss_index': index,\n",
    "        'api_key': api_key\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Code Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_for_task(pipeline, task_description, n_examples=3, \n",
    "                           generation_model=\"deepseek/deepseek-chat-v3.1:free\", verbose=True):\n",
    "\n",
    "    # Retrieve similar examples (higher similarity = more similar)\n",
    "    similarities, indices = search_similar(\n",
    "        task_description,\n",
    "        pipeline['embedding_model'],\n",
    "        pipeline['faiss_index'],\n",
    "        k=n_examples\n",
    "    )\n",
    "    \n",
    "    retrieved_examples = [pipeline['examples'][idx] for idx in indices]\n",
    "    \n",
    "    # Generate code\n",
    "    generated_code = generate_code(\n",
    "        task_description,\n",
    "        retrieved_examples,\n",
    "        pipeline['api_key'],\n",
    "        model=generation_model\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"task_description\": task_description,\n",
    "        \"generated_code\": generated_code,\n",
    "        \"retrieved_examples\": [\n",
    "            {\n",
    "                \"task_id\": ex['task_id'],\n",
    "                \"prompt\": ex['prompt'],\n",
    "                \"canonical_solution\": ex['canonical_solution'],\n",
    "                \"similarity\": float(sim)\n",
    "            }\n",
    "            for ex, sim in zip(retrieved_examples, similarities)\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    \"\"\"Pretty print the generation result.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TASK DESCRIPTION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result[\"task_description\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATED CODE:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result[\"generated_code\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RETRIEVED EXAMPLES:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, ex in enumerate(result[\"retrieved_examples\"], 1):\n",
    "        print(f\"\\n{i}. {ex['task_id']} (cosine similarity: {ex['similarity']:.4f})\")\n",
    "        print(f\"   {ex['prompt']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Initialize the Pipeline\n",
    "\n",
    "Run this cell to set up the entire RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Setting up RAG Pipeline with Normalized FAISS\n",
      "================================================================================\n",
      "\n",
      "Loading HumanEval dataset...\n",
      "✓ Loaded 164 examples\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Creating embeddings for 164 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f300e0796c4ff3bf25d2b2d7b916fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created embeddings with shape: (164, 384)\n",
      "Building normalized FAISS index with Inner Product...\n",
      "✓ Normalized 164 vectors\n",
      "✓ FAISS index built with 164 vectors\n",
      "  Using: IndexIDMap(IndexFlatIP) for cosine similarity\n",
      "\n",
      " ✓ Pipeline setup complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = setup_rag_pipeline(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Example 1: Calculate Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      "TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    \"\"\" Calculate the median of a list of numbers.\n",
      "    >>> calculate_median([3, 1, 2, 4, 5])\n",
      "    3.0\n",
      "    >>> calculate_median([1, 2, 3, 4])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    sorted_numbers = sorted(numbers)\n",
      "    n = len(sorted_numbers)\n",
      "    if n % 2 == 1:\n",
      "        return float(sorted_numbers[n // 2])\n",
      "    else:\n",
      "        return (sorted_numbers[n // 2 - 1] + sorted_numbers[n // 2]) / 2.0\n",
      "\n",
      "================================================================================\n",
      "RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/47 (cosine similarity: 0.8026)\n",
      "   \n",
      "\n",
      "def median(l: list):\n",
      "    \"\"\"Return median of elements in the list l.\n",
      "    >>> median([3, 1, 2, 4, 5])\n",
      "    3\n",
      "    >>> median([-10, 4, 6, 1000, 10, 20])\n",
      "    15.0\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/4 (cosine similarity: 0.6628)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/21 (cosine similarity: 0.5341)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def rescale_to_unit(numbers: List[float]) -> List[float]:\n",
      "    \"\"\" Given list of numbers (of at least two elements), apply a linear transform to that list,\n",
      "    such that the smallest number will become 0 and the largest will become 1\n",
      "    >>> rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0])\n",
      "    [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "    \"\"\"\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "task1 = \"\"\"\n",
    "def calculate_median(numbers: List[float]) -> float:\n",
    "    \\\"\\\"\\\" Calculate the median of a list of numbers.\n",
    "    >>> calculate_median([3, 1, 2, 4, 5])\n",
    "    3.0\n",
    "    >>> calculate_median([1, 2, 3, 4])\n",
    "    2.5\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result1 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task1,\n",
    "    n_examples=3,\n",
    "    generation_model=\"deepseek/deepseek-chat-v3.1:free\"\n",
    ")\n",
    "\n",
    "print_result(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Example 2: Palindrome Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      "TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def is_palindrome(s: str) -> bool:\n",
      "    \"\"\" Check if a string is a palindrome (ignoring spaces and case).\n",
      "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
      "    True\n",
      "    >>> is_palindrome(\"hello\")\n",
      "    False\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED CODE:\n",
      "================================================================================\n",
      "def is_palindrome(s: str) -> bool:\n",
      "    \"\"\" Check if a string is a palindrome (ignoring spaces and case).\n",
      "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
      "    True\n",
      "    >>> is_palindrome(\"hello\")\n",
      "    False\n",
      "    \"\"\"\n",
      "    cleaned = ''.join(c.lower() for c in s if not c.isspace())\n",
      "    return cleaned == cleaned[::-1]\n",
      "\n",
      "================================================================================\n",
      "RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/48 (cosine similarity: 0.8870)\n",
      "   \n",
      "\n",
      "def is_palindrome(text: str):\n",
      "    \"\"\"\n",
      "    Checks if given string is a palindrome\n",
      "    >>> is_palindrome('')\n",
      "    True\n",
      "    >>> is_palindrome('aba')\n",
      "    True\n",
      "    >>> is_palindrome('aaaaa')\n",
      "    True\n",
      "    >>> is_palindrome('zbcd')\n",
      "    False\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/10 (cosine similarity: 0.7355)\n",
      "   \n",
      "\n",
      "def is_palindrome(string: str) -> bool:\n",
      "    \"\"\" Test if given string is a palindrome \"\"\"\n",
      "    return string == string[::-1]\n",
      "\n",
      "\n",
      "def make_palindrome(string: str) -> str:\n",
      "    \"\"\" Find the shortest palindrome that begins with a supplied string.\n",
      "    Algorithm idea is simple:\n",
      "    - Find the longest postfix of supplied string that is a palindrome.\n",
      "    - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n",
      "    >>> make_palindrome('')\n",
      "    ''\n",
      "    >>> make_palindrome('cat')\n",
      "    'catac'\n",
      "    >>> make_palindrome('cata')\n",
      "    'catac'\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/112 (cosine similarity: 0.6228)\n",
      "   \n",
      "def reverse_delete(s,c):\n",
      "    \"\"\"Task\n",
      "    We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n",
      "    then check if the result string is palindrome.\n",
      "    A string is called palindrome if it reads the same backward as forward.\n",
      "    You should return a tuple containing the result string and True/False for the check.\n",
      "    Example\n",
      "    For s = \"abcde\", c = \"ae\", the result should be ('bcd',False)\n",
      "    For s = \"abcdef\", c = \"b\"  the result should be ('acdef',False)\n",
      "    For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',True)\n",
      "    \"\"\"\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "task2 = \"\"\"\n",
    "def is_palindrome(s: str) -> bool:\n",
    "    \\\"\\\"\\\" Check if a string is a palindrome (ignoring spaces and case).\n",
    "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
    "    True\n",
    "    >>> is_palindrome(\"hello\")\n",
    "    False\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result2 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task2,\n",
    "    n_examples=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print_result(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Example 3: Custom Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      "TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def find_duplicates(nums: List[int]) -> List[int]:\n",
      "    \"\"\" Find all duplicate numbers in a list.\n",
      "    >>> find_duplicates([1, 2, 3, 2, 4, 3])\n",
      "    [2, 3]\n",
      "    >>> find_duplicates([1, 2, 3, 4])\n",
      "    []\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "import collections\n",
      "\n",
      "def find_duplicates(nums: List[int]) -> List[int]:\n",
      "    \"\"\" Find all duplicate numbers in a list.\n",
      "    >>> find_duplicates([1, 2, 3, 2, 4, 3])\n",
      "    [2, 3]\n",
      "    >>> find_duplicates([1, 2, 3, 4])\n",
      "    []\n",
      "    \"\"\"\n",
      "    c = collections.Counter(nums)\n",
      "    return sorted([n for n in set(nums) if c[n] > 1])\n",
      "\n",
      "================================================================================\n",
      "RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/26 (cosine similarity: 0.7875)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def remove_duplicates(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a list of integers, remove all elements that occur more than once.\n",
      "    Keep order of elements left the same as in the input.\n",
      "    >>> remove_duplicates([1, 2, 3, 2, 4])\n",
      "    [1, 3, 4]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/34 (cosine similarity: 0.6059)\n",
      "   \n",
      "\n",
      "def unique(l: list):\n",
      "    \"\"\"Return sorted unique elements in a list\n",
      "    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n",
      "    [0, 2, 3, 5, 9, 123]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/104 (cosine similarity: 0.5869)\n",
      "   \n",
      "def unique_digits(x):\n",
      "    \"\"\"Given a list of positive integers x. return a sorted list of all \n",
      "    elements that hasn't any even digit.\n",
      "\n",
      "    Note: Returned list should be sorted in increasing order.\n",
      "    \n",
      "    For example:\n",
      "    >>> unique_digits([15, 33, 1422, 1])\n",
      "    [1, 15, 33]\n",
      "    >>> unique_digits([152, 323, 1422, 10])\n",
      "    []\n",
      "    \"\"\"\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Define your own task here\n",
    "custom_task = \"\"\"\n",
    "def find_duplicates(nums: List[int]) -> List[int]:\n",
    "    \\\"\\\"\\\" Find all duplicate numbers in a list.\n",
    "    >>> find_duplicates([1, 2, 3, 2, 4, 3])\n",
    "    [2, 3]\n",
    "    >>> find_duplicates([1, 2, 3, 4])\n",
    "    []\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result_custom = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=custom_task,\n",
    "    n_examples=3\n",
    ")\n",
    "\n",
    "print_result(result_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save/Load FAISS Index (Optional)\n",
    "\n",
    "Save the index to disk for faster future runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Index saved to humaneval_faiss_index.bin\n"
     ]
    }
   ],
   "source": [
    "# Save index\n",
    "faiss.write_index(pipeline['faiss_index'], \"humaneval_faiss_index.bin\")\n",
    "print(\"✓ Index saved to humaneval_faiss_index.bin\")\n",
    "\n",
    "# To load later:\n",
    "# loaded_index = faiss.read_index(\"humaneval_faiss_index.bin\")\n",
    "# pipeline['faiss_index'] = loaded_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've successfully created a RAG code generation system that:\n",
    "- Loads the HumanEval dataset\n",
    "- Creates embeddings using Sentence Transformers\n",
    "- Builds a FAISS vector index for fast retrieval\n",
    "- Retrieves similar code examples\n",
    "- Generates new code using open-source LLMs via OpenRouter\n",
    "\n",
    "### Next Steps:\n",
    "1. Try different embedding models for better retrieval\n",
    "2. Experiment with various generation models\n",
    "3. Adjust `n_examples` based on task complexity\n",
    "4. Save the index for faster future runs\n",
    "5. Implement evaluation metrics for generated code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
