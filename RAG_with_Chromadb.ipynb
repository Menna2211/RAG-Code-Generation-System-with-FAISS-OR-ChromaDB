{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc0c35f",
   "metadata": {},
   "source": [
    "# RAG Code Generation System with ChromaDB\n",
    "\n",
    "This notebook implements a RAG system using **ChromaDB** for persistent vector storage.\n",
    "\n",
    "## Advantages of ChromaDB:\n",
    "- **Persistent Storage**: Data persists between sessions\n",
    "- **Built-in Metadata**: Easy metadata management\n",
    "- **Simple API**: More intuitive than FAISS\n",
    "- **No Manual Index Saving**: Auto-persists to disk\n",
    "\n",
    "## Table of Contents\n",
    "1. Installation & Setup\n",
    "2. Dataset Loading\n",
    "3. ChromaDB Collection Setup\n",
    "4. Code Generation\n",
    "5. Examples & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838f7db",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b620fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets sentence-transformers chromadb openai python-dotenv torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb037f",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5ffc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\NLP Cellula\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1525a3",
   "metadata": {},
   "source": [
    "## 3. Setup API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8349c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your OpenRouter API key\n",
    "OPENROUTER_API_KEY = getpass(\"Enter your OpenRouter API key: \")\n",
    "\n",
    "# Or set it directly\n",
    "# OPENROUTER_API_KEY = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83d757",
   "metadata": {},
   "source": [
    "## 4. Dataset Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884b7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_humaneval_dataset():\n",
    "    \"\"\"Load and process the HumanEval dataset.\"\"\"\n",
    "    print(\"Loading HumanEval dataset...\")\n",
    "    dataset = load_dataset(\"openai/openai_humaneval\", split=\"test\")\n",
    "    \n",
    "    examples = []\n",
    "    for item in dataset:\n",
    "        examples.append({\n",
    "            'task_id': item['task_id'],\n",
    "            'prompt': item['prompt'],\n",
    "            'canonical_solution': item['canonical_solution'],\n",
    "            'entry_point': item['entry_point']\n",
    "        })\n",
    "    \n",
    "    print(f\"✓ Loaded {len(examples)} examples\")\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f89aa",
   "metadata": {},
   "source": [
    "## 5. ChromaDB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d84299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_client(persist_directory=\"./chroma_codegen\"):\n",
    "    \"\"\"Create and return ChromaDB client.\"\"\"\n",
    "    print(f\"Creating ChromaDB client with persist directory: {persist_directory}\")\n",
    "    client = chromadb.Client(Settings(\n",
    "        persist_directory=persist_directory,\n",
    "        anonymized_telemetry=False\n",
    "    ))\n",
    "    print(\"✓ ChromaDB client created\")\n",
    "    return client\n",
    "\n",
    "\n",
    "def setup_chroma_collection(client, examples, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\", force_reload=False):\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"humaneval_code_examples\",\n",
    "        metadata={\"description\": \"HumanEval code examples for RAG\"}\n",
    "    )\n",
    "    \n",
    "    # Load embedding model\n",
    "    print(f\"Loading embedding model: {embedding_model_name}\")\n",
    "    embedding_model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    # Check if collection already has data\n",
    "    if collection.count() > 0 and not force_reload:\n",
    "        print(f\"✓ Collection already contains {collection.count()} examples\")\n",
    "        print(\"   Set force_reload=True to reload data\")\n",
    "        return collection, embedding_model\n",
    "    \n",
    "    # If force reload, clear collection\n",
    "    if force_reload and collection.count() > 0:\n",
    "        print(\"Clearing existing collection...\")\n",
    "        client.delete_collection(\"humaneval_code_examples\")\n",
    "        collection = client.create_collection(\n",
    "            name=\"humaneval_code_examples\",\n",
    "            metadata={\"description\": \"HumanEval code examples for RAG\"}\n",
    "        )\n",
    "    \n",
    "    # Prepare data for ChromaDB\n",
    "    print(\"Preparing data...\")\n",
    "    ids = []\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    \n",
    "    for example in examples:\n",
    "        ids.append(example['task_id'])\n",
    "        documents.append(example['prompt'])\n",
    "        metadatas.append({\n",
    "            'task_id': example['task_id'],\n",
    "            'entry_point': example['entry_point'],\n",
    "            'canonical_solution': example['canonical_solution']\n",
    "        })\n",
    "    \n",
    "    # Generate embeddings\n",
    "    print(\"Creating embeddings...\")\n",
    "    embeddings_list = embedding_model.encode(documents, show_progress_bar=True).tolist()\n",
    "    \n",
    "    # Add to ChromaDB\n",
    "    print(\"Adding to ChromaDB collection...\")\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        embeddings=embeddings_list,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Collection contains {collection.count()} examples\")\n",
    "    return collection, embedding_model\n",
    "\n",
    "\n",
    "def retrieve_similar(query, collection, embedding_model, n_results=3):\n",
    "    \"\"\"Retrieve similar code examples from ChromaDB.\"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query]).tolist()\n",
    "    \n",
    "    # Search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    similar_examples = []\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        similar_examples.append({\n",
    "            'task_id': results['ids'][0][i],\n",
    "            'prompt': results['documents'][0][i],\n",
    "            'canonical_solution': results['metadatas'][0][i]['canonical_solution'],\n",
    "            'entry_point': results['metadatas'][0][i]['entry_point'],\n",
    "            'distance': results['distances'][0][i]\n",
    "        })\n",
    "    \n",
    "    return similar_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e51ef",
   "metadata": {},
   "source": [
    "## 6. Code Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ef74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(examples):\n",
    "    \"\"\"Build context string from retrieved examples.\"\"\"\n",
    "    context_parts = []\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        context_parts.append(f\"Example {i}:\")\n",
    "        context_parts.append(f\"Task: {ex['prompt'].strip()}\")\n",
    "        context_parts.append(f\"Solution:\\n{ex['canonical_solution'].strip()}\")\n",
    "        context_parts.append(\"\")\n",
    "    return \"\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "def extract_code(response):\n",
    "    \"\"\"Extract code from LLM response.\"\"\"\n",
    "    if \"```python\" in response:\n",
    "        start = response.find(\"```python\") + len(\"```python\")\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    elif \"```\" in response:\n",
    "        start = response.find(\"```\") + 3\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def generate_code(task_description, retrieved_examples, api_key,\n",
    "                 model, max_tokens=500, temperature=0.2):\n",
    "    \"\"\"Generate code using OpenRouter API.\"\"\"\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    context = build_context(retrieved_examples)\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following examples of Python coding tasks and solutions, generate a complete function for the new task.\n",
    "\n",
    "{context}\n",
    "\n",
    "New Task:\n",
    "{task_description}\n",
    "\n",
    "Generate a complete, working Python function that solves this task. Include the function signature and implementation. Only return the code, no explanations.\"\"\"\n",
    "    \n",
    "    print(\" Generating code...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert Python programmer. Generate clean, efficient, and well-documented code.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return extract_code(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073845b",
   "metadata": {},
   "source": [
    "## 7. Main Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a315b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chromadb_pipeline(api_key, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                           persist_directory=\"./chroma_codegen\", force_reload=False):\n",
    "    print(\"=\"*80)\n",
    "    print(\" Setting up ChromaDB RAG Pipeline\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load dataset\n",
    "    examples = load_humaneval_dataset()\n",
    "    \n",
    "    # Create ChromaDB client\n",
    "    client = create_chroma_client(persist_directory)\n",
    "    \n",
    "    # Setup collection with embeddings\n",
    "    collection, embedding_model = setup_chroma_collection(\n",
    "        client, examples, embedding_model_name, force_reload\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ Pipeline setup complete!\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'client': client,\n",
    "        'collection': collection,\n",
    "        'embedding_model': embedding_model,\n",
    "        'api_key': api_key,\n",
    "        'examples': examples\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_code_for_task(pipeline, task_description, n_examples=3,\n",
    "                           generation_model=\"deepseek/deepseek-chat-v3.1:free\", verbose=True):\n",
    "\n",
    "    # Retrieve similar examples\n",
    "    retrieved_examples = retrieve_similar(\n",
    "        task_description,\n",
    "        pipeline['collection'],\n",
    "        pipeline['embedding_model'],\n",
    "        n_results=n_examples\n",
    "    )\n",
    "    \n",
    "    # Generate code\n",
    "    generated_code = generate_code(\n",
    "        task_description,\n",
    "        retrieved_examples,\n",
    "        pipeline['api_key'],\n",
    "        model=generation_model\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'task_description': task_description,\n",
    "        'generated_code': generated_code,\n",
    "        'retrieved_examples': retrieved_examples\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8d4ea",
   "metadata": {},
   "source": [
    "## 8. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce3a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    \"\"\"Pretty print the generation result.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" TASK DESCRIPTION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result['task_description'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" GENERATED CODE:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result['generated_code'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" RETRIEVED EXAMPLES:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, ex in enumerate(result['retrieved_examples'], 1):\n",
    "        print(f\"\\n{i}. {ex['task_id']} (distance: {ex['distance']:.4f})\")\n",
    "        print(f\"   {ex['prompt']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369de6e1",
   "metadata": {},
   "source": [
    "## 9. Initialize the Pipeline\n",
    "\n",
    "**Note**: ChromaDB persists data automatically! After first run, subsequent runs will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444daa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Setting up ChromaDB RAG Pipeline\n",
      "================================================================================\n",
      "\n",
      "Loading HumanEval dataset...\n",
      "✓ Loaded 164 examples\n",
      "Creating ChromaDB client with persist directory: ./chroma_codegen\n",
      "✓ ChromaDB client created\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Preparing data...\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a492275c844640bc68d91437f15503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to ChromaDB collection...\n",
      "✓ Collection contains 164 examples\n",
      "\n",
      "================================================================================\n",
      "✓ Pipeline setup complete!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "# Set force_reload=True only if you want to reload the dataset\n",
    "pipeline = setup_chromadb_pipeline(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    persist_directory=\"./chroma_codegen\",\n",
    "    force_reload=False  # Set to True to reload data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e6144",
   "metadata": {},
   "source": [
    "## 10. Example 1: Maximum Subarray Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80234b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      " TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def find_max_subarray_sum(arr: List[int]) -> int:\n",
      "    \"\"\" Find the maximum sum of a contiguous subarray (Kadane's algorithm).\n",
      "    >>> find_max_subarray_sum([-2, 1, -3, 4, -1, 2, 1, -5, 4])\n",
      "    6\n",
      "    >>> find_max_subarray_sum([1, 2, 3, 4])\n",
      "    10\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      " GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "\n",
      "def find_max_subarray_sum(arr: List[int]) -> int:\n",
      "    max_current = max_global = arr[0]\n",
      "    for i in range(1, len(arr)):\n",
      "        max_current = max(arr[i], max_current + arr[i])\n",
      "        if max_current > max_global:\n",
      "            max_global = max_current\n",
      "    return max_global\n",
      "\n",
      "================================================================================\n",
      " RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/120 (distance: 0.7802)\n",
      "   \n",
      "def maximum(arr, k):\n",
      "    \"\"\"\n",
      "    Given an array arr of integers and a positive integer k, return a sorted list \n",
      "    of length k with the maximum k numbers in arr.\n",
      "\n",
      "    Example 1:\n",
      "\n",
      "        Input: arr = [-3, -4, 5], k = 3\n",
      "        Output: [-4, -3, 5]\n",
      "\n",
      "    Example 2:\n",
      "\n",
      "        Input: arr = [4, -4, 4], k = 2\n",
      "        Output: [4, 4]\n",
      "\n",
      "    Example 3:\n",
      "\n",
      "        Input: arr = [-3, 2, 1, 2, -1, -2, 1], k = 1\n",
      "        Output: [2]\n",
      "\n",
      "    Note:\n",
      "        1. The length of the array will be in the range of [1, 1000].\n",
      "        2. The elements in the array will be in the range of [-1000, 1000].\n",
      "        3. 0 <= k <= len(arr)\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/114 (distance: 0.9218)\n",
      "   \n",
      "def minSubArraySum(nums):\n",
      "    \"\"\"\n",
      "    Given an array of integers nums, find the minimum sum of any non-empty sub-array\n",
      "    of nums.\n",
      "    Example\n",
      "    minSubArraySum([2, 3, 4, 1, 2, 4]) == 1\n",
      "    minSubArraySum([-1, -2, -3]) == -6\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/35 (distance: 0.9566)\n",
      "   \n",
      "\n",
      "def max_element(l: list):\n",
      "    \"\"\"Return maximum element in the list.\n",
      "    >>> max_element([1, 2, 3])\n",
      "    3\n",
      "    >>> max_element([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n",
      "    123\n",
      "    \"\"\"\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "task1 = \"\"\"\n",
    "def find_max_subarray_sum(arr: List[int]) -> int:\n",
    "    \\\"\\\"\\\" Find the maximum sum of a contiguous subarray (Kadane's algorithm).\n",
    "    >>> find_max_subarray_sum([-2, 1, -3, 4, -1, 2, 1, -5, 4])\n",
    "    6\n",
    "    >>> find_max_subarray_sum([1, 2, 3, 4])\n",
    "    10\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result1 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task1,\n",
    "    n_examples=3\n",
    ")\n",
    "\n",
    "print_result(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a2677",
   "metadata": {},
   "source": [
    "## 11. Example 2: Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5cf6a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      " TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def remove_duplicates(nums: List[int]) -> List[int]:\n",
      "    \"\"\" Remove duplicates from a list while preserving order.\n",
      "    >>> remove_duplicates([1, 1, 2, 2, 3, 4, 4])\n",
      "    [1, 2, 3, 4]\n",
      "    >>> remove_duplicates([1, 2, 3])\n",
      "    [1, 2, 3]\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      " GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "\n",
      "def remove_duplicates(nums: List[int]) -> List[int]:\n",
      "    seen = set()\n",
      "    result = []\n",
      "    for num in nums:\n",
      "        if num not in seen:\n",
      "            seen.add(num)\n",
      "            result.append(num)\n",
      "    return result\n",
      "\n",
      "================================================================================\n",
      " RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/26 (distance: 0.2354)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def remove_duplicates(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a list of integers, remove all elements that occur more than once.\n",
      "    Keep order of elements left the same as in the input.\n",
      "    >>> remove_duplicates([1, 2, 3, 2, 4])\n",
      "    [1, 3, 4]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/34 (distance: 0.7434)\n",
      "   \n",
      "\n",
      "def unique(l: list):\n",
      "    \"\"\"Return sorted unique elements in a list\n",
      "    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n",
      "    [0, 2, 3, 5, 9, 123]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/126 (distance: 0.8228)\n",
      "   \n",
      "def is_sorted(lst):\n",
      "    '''\n",
      "    Given a list of numbers, return whether or not they are sorted\n",
      "    in ascending order. If list has more than 1 duplicate of the same\n",
      "    number, return False. Assume no negative numbers and only integers.\n",
      "\n",
      "    Examples\n",
      "    is_sorted([5]) ➞ True\n",
      "    is_sorted([1, 2, 3, 4, 5]) ➞ True\n",
      "    is_sorted([1, 3, 2, 4, 5]) ➞ False\n",
      "    is_sorted([1, 2, 3, 4, 5, 6]) ➞ True\n",
      "    is_sorted([1, 2, 3, 4, 5, 6, 7]) ➞ True\n",
      "    is_sorted([1, 3, 2, 4, 5, 6, 7]) ➞ False\n",
      "    is_sorted([1, 2, 2, 3, 3, 4]) ➞ True\n",
      "    is_sorted([1, 2, 2, 2, 3, 4]) ➞ False\n",
      "    '''\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "task2 = \"\"\"\n",
    "def remove_duplicates(nums: List[int]) -> List[int]:\n",
    "    \\\"\\\"\\\" Remove duplicates from a list while preserving order.\n",
    "    >>> remove_duplicates([1, 1, 2, 2, 3, 4, 4])\n",
    "    [1, 2, 3, 4]\n",
    "    >>> remove_duplicates([1, 2, 3])\n",
    "    [1, 2, 3]\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result2 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task2,\n",
    "    n_examples=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print_result(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae85816",
   "metadata": {},
   "source": [
    "## 12. Example 3: Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abbfc5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating code...\n",
      "\n",
      "================================================================================\n",
      " TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def binary_search(arr: List[int], target: int) -> int:\n",
      "    \"\"\" Perform binary search on a sorted array. Return index or -1.\n",
      "    >>> binary_search([1, 2, 3, 4, 5, 6, 7], 5)\n",
      "    4\n",
      "    >>> binary_search([1, 2, 3, 4, 5], 10)\n",
      "    -1\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      " GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "\n",
      "def binary_search(arr: List[int], target: int) -> int:\n",
      "    left, right = 0, len(arr) - 1\n",
      "    while left <= right:\n",
      "        mid = (left + right) // 2\n",
      "        if arr[mid] == target:\n",
      "            return mid\n",
      "        elif arr[mid] < target:\n",
      "            left = mid + 1\n",
      "        else:\n",
      "            right = mid - 1\n",
      "    return -1\n",
      "\n",
      "================================================================================\n",
      " RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/116 (distance: 0.7351)\n",
      "   \n",
      "def sort_array(arr):\n",
      "    \"\"\"\n",
      "    In this Kata, you have to sort an array of non-negative integers according to\n",
      "    number of ones in their binary representation in ascending order.\n",
      "    For similar number of ones, sort based on decimal value.\n",
      "\n",
      "    It must be implemented like this:\n",
      "    >>> sort_array([1, 5, 2, 3, 4]) == [1, 2, 3, 4, 5]\n",
      "    >>> sort_array([-2, -3, -4, -5, -6]) == [-6, -5, -4, -3, -2]\n",
      "    >>> sort_array([1, 0, 2, 3, 4]) [0, 1, 2, 3, 4]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "2. HumanEval/69 (distance: 0.7601)\n",
      "   \n",
      "def search(lst):\n",
      "    '''\n",
      "    You are given a non-empty list of positive integers. Return the greatest integer that is greater than \n",
      "    zero, and has a frequency greater than or equal to the value of the integer itself. \n",
      "    The frequency of an integer is the number of times it appears in the list.\n",
      "    If no such a value exist, return -1.\n",
      "    Examples:\n",
      "        search([4, 1, 2, 2, 3, 1]) == 2\n",
      "        search([1, 2, 2, 3, 3, 3, 4, 4, 4]) == 3\n",
      "        search([5, 5, 4, 4, 4]) == -1\n",
      "    '''\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "task3 = \"\"\"\n",
    "def binary_search(arr: List[int], target: int) -> int:\n",
    "    \\\"\\\"\\\" Perform binary search on a sorted array. Return index or -1.\n",
    "    >>> binary_search([1, 2, 3, 4, 5, 6, 7], 5)\n",
    "    4\n",
    "    >>> binary_search([1, 2, 3, 4, 5], 10)\n",
    "    -1\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result3 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task3,\n",
    "    n_examples=2\n",
    ")\n",
    "\n",
    "print_result(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad431b",
   "metadata": {},
   "source": [
    "## 13. Inspect ChromaDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d09565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Name: humaneval_code_examples\n",
      "Total Documents: 164\n",
      "\n",
      "Metadata: {'description': 'HumanEval code examples for RAG'}\n",
      "\n",
      "\n",
      "Sample Documents:\n",
      "================================================================================\n",
      "\n",
      "1. ID: HumanEval/0\n",
      "   Document: from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given thr...\n",
      "\n",
      "2. ID: HumanEval/1\n",
      "   Document: from typing import List\n",
      "\n",
      "\n",
      "def separate_paren_groups(paren_string: str) -> List[str]:\n",
      "    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\n",
      "    se...\n",
      "\n",
      "3. ID: HumanEval/2\n",
      "   Document: \n",
      "\n",
      "def truncate_number(number: float) -> float:\n",
      "    \"\"\" Given a positive floating point number, it can be decomposed into\n",
      "    and integer part (largest integer smaller than given number) and decimals\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "# Get collection statistics\n",
    "collection = pipeline['collection']\n",
    "\n",
    "print(f\"Collection Name: {collection.name}\")\n",
    "print(f\"Total Documents: {collection.count()}\")\n",
    "print(f\"\\nMetadata: {collection.metadata}\")\n",
    "\n",
    "# Peek at first 3 documents\n",
    "sample = collection.peek(3)\n",
    "print(f\"\\n\\nSample Documents:\")\n",
    "print(\"=\"*80)\n",
    "for i, (doc_id, doc) in enumerate(zip(sample['ids'], sample['documents']), 1):\n",
    "    print(f\"\\n{i}. ID: {doc_id}\")\n",
    "    print(f\"   Document: {doc[:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
