{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Code Generation System with FAISS\n",
    "\n",
    "This notebook implements a complete RAG (Retrieval-Augmented Generation) system for code generation using:\n",
    "- **HumanEval Dataset**: For code examples\n",
    "- **Sentence Transformers**: For embeddings\n",
    "- **FAISS**: For vector similarity search\n",
    "- **OpenRouter API**: For code generation with open-source LLMs\n",
    "\n",
    "## Table of Contents\n",
    "1. Installation\n",
    "2. Dataset Loading\n",
    "3. Embedding Creation\n",
    "4. Vector Index Building\n",
    "5. Code Generation\n",
    "6. Examples & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sentence-transformers faiss-cpu openai python-dotenv torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup API Key\n",
    "\n",
    "Get your OpenRouter API key from: https://openrouter.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your OpenRouter API key\n",
    "OPENROUTER_API_KEY = getpass(\"Enter your OpenRouter API key: \")\n",
    "\n",
    "# Or set it directly (not recommended for shared notebooks)\n",
    "# OPENROUTER_API_KEY = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Functions\n",
    "\n",
    "Load and process the HumanEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_humaneval_dataset():\n",
    "    \"\"\"Load and process the HumanEval dataset.\"\"\"\n",
    "    print(\"Loading HumanEval dataset...\")\n",
    "    dataset = load_dataset(\"openai/openai_humaneval\", split=\"test\")\n",
    "    \n",
    "    examples = []\n",
    "    for item in dataset:\n",
    "        examples.append({\n",
    "            'task_id': item['task_id'],\n",
    "            'prompt': item['prompt'],\n",
    "            'canonical_solution': item['canonical_solution'],\n",
    "            'entry_point': item['entry_point']\n",
    "        })\n",
    "    \n",
    "    print(f\"✓ Loaded {len(examples)} examples\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "def extract_prompts(examples):\n",
    "    \"\"\"Extract all prompts from examples.\"\"\"\n",
    "    return [ex['prompt'] for ex in examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(texts, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Create embeddings for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings\n",
    "        model_name: Name of the sentence transformer model\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, embeddings_array)\n",
    "    \"\"\"\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    print(f\"Creating embeddings for {len(texts)} texts...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    embeddings_array = np.array(embeddings).astype('float32')\n",
    "    \n",
    "    print(f\"✓ Created embeddings with shape: {embeddings_array.shape}\")\n",
    "    return model, embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FAISS Index Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index_normalized(embeddings, doc_ids=None):\n",
    "    \"\"\"\n",
    "    Build normalized FAISS index using Inner Product for cosine similarity.\n",
    "    \n",
    "    This is better than L2 distance for semantic similarity because:\n",
    "    - Normalized vectors + Inner Product = Cosine Similarity\n",
    "    - Cosine similarity is direction-based, not magnitude-based\n",
    "    - More accurate for text embeddings\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Numpy array of embeddings\n",
    "        doc_ids: Optional array of document IDs (uses indices if None)\n",
    "        \n",
    "    Returns:\n",
    "        FAISS IndexIDMap with normalized vectors\n",
    "    \"\"\"\n",
    "    print(\"Building normalized FAISS index with Inner Product...\")\n",
    "    \n",
    "    # Get dimension\n",
    "    dim = embeddings.shape[1]\n",
    "    \n",
    "    # Normalize embeddings to unit length (L2 normalization)\n",
    "    # This makes Inner Product equivalent to Cosine Similarity\n",
    "    norm_embeddings = embeddings.copy()\n",
    "    faiss.normalize_L2(norm_embeddings)\n",
    "    print(f\"✓ Normalized {len(norm_embeddings)} vectors\")\n",
    "    \n",
    "    # Create IDs if not provided\n",
    "    if doc_ids is None:\n",
    "        doc_ids = np.arange(len(embeddings)).astype('int64')\n",
    "    else:\n",
    "        doc_ids = np.array(doc_ids).astype('int64')\n",
    "    \n",
    "    # Create Inner Product index (faster and more accurate for normalized vectors)\n",
    "    base_index = faiss.IndexFlatIP(dim)\n",
    "    \n",
    "    # Wrap with IndexIDMap to maintain document IDs\n",
    "    faiss_index = faiss.IndexIDMap(base_index)\n",
    "    \n",
    "    # Add normalized vectors with IDs\n",
    "    faiss_index.add_with_ids(norm_embeddings, doc_ids)\n",
    "    \n",
    "    print(f\"✓ FAISS index built with {faiss_index.ntotal} vectors\")\n",
    "    print(f\"  Using: IndexIDMap(IndexFlatIP) for cosine similarity\")\n",
    "    \n",
    "    return faiss_index\n",
    "\n",
    "\n",
    "def search_similar(query, embedding_model, faiss_index, k=3):\n",
    "    \"\"\"\n",
    "    Search for k most similar examples using cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        query: Query text\n",
    "        embedding_model: Sentence transformer model\n",
    "        faiss_index: FAISS IndexIDMap\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (similarities, indices)\n",
    "        Note: Higher similarity = more similar (opposite of L2 distance)\n",
    "    \"\"\"\n",
    "    # Encode query\n",
    "    query_embedding = embedding_model.encode([query]).astype('float32')\n",
    "    \n",
    "    # Normalize query vector\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    # Search (returns similarity scores, not distances)\n",
    "    similarities, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    return similarities[0], indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(examples):\n",
    "    \"\"\"Build context string from retrieved examples.\"\"\"\n",
    "    context_parts = []\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        context_parts.append(f\"Example {i}:\")\n",
    "        context_parts.append(f\"Task: {ex['prompt'].strip()}\")\n",
    "        context_parts.append(f\"Solution:\\n{ex['canonical_solution'].strip()}\")\n",
    "        context_parts.append(\"\")\n",
    "    return \"\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "def create_prompt(task_description, context):\n",
    "    \"\"\"Create the full prompt for code generation.\"\"\"\n",
    "    return f\"\"\"Based on the following examples of Python coding tasks and solutions, generate a complete function for the new task.\n",
    "\n",
    "{context}\n",
    "\n",
    "New Task:\n",
    "{task_description}\n",
    "\n",
    "Generate a complete, working Python function that solves this task. Include the function signature and implementation. Only return the code, no explanations.\"\"\"\n",
    "\n",
    "\n",
    "def extract_code(response):\n",
    "    \"\"\"Extract code from the LLM response.\"\"\"\n",
    "    if \"```python\" in response:\n",
    "        start = response.find(\"```python\") + len(\"```python\")\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    elif \"```\" in response:\n",
    "        start = response.find(\"```\") + 3\n",
    "        end = response.find(\"```\", start)\n",
    "        return response[start:end].strip()\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def generate_code(task_description, retrieved_examples, api_key, \n",
    "                 model=\"deepseek/deepseek-coder\", max_tokens=500, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Generate code using OpenRouter API.\n",
    "    \n",
    "    Args:\n",
    "        task_description: Natural language description of the task\n",
    "        retrieved_examples: List of similar code examples\n",
    "        api_key: OpenRouter API key\n",
    "        model: Model name to use\n",
    "        max_tokens: Maximum tokens for generation\n",
    "        temperature: Temperature for generation\n",
    "        \n",
    "    Returns:\n",
    "        Generated code as a string\n",
    "    \"\"\"\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=api_key\n",
    "    )\n",
    "    \n",
    "    context = build_context(retrieved_examples)\n",
    "    prompt = create_prompt(task_description, context)\n",
    "    \n",
    "    print(\"🤖 Generating code...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert Python programmer. Generate clean, efficient, and well-documented code.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    generated_code = response.choices[0].message.content\n",
    "    return extract_code(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline(api_key, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Setup the complete RAG pipeline with normalized FAISS index.\n",
    "    \n",
    "    Args:\n",
    "        api_key: OpenRouter API key\n",
    "        embedding_model_name: Name of embedding model to use\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all pipeline components\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🚀 Setting up RAG Pipeline with Normalized FAISS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Load dataset\n",
    "    examples = load_humaneval_dataset()\n",
    "    \n",
    "    # Create embeddings\n",
    "    prompts = extract_prompts(examples)\n",
    "    embedding_model, embeddings = create_embeddings(prompts, embedding_model_name)\n",
    "    \n",
    "    # Build normalized FAISS index with Inner Product\n",
    "    index = build_faiss_index_normalized(embeddings)\n",
    "    \n",
    "    print(\"\\n✓ Pipeline setup complete!\\n\")\n",
    "    \n",
    "    return {\n",
    "        'examples': examples,\n",
    "        'embedding_model': embedding_model,\n",
    "        'faiss_index': index,\n",
    "        'api_key': api_key\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Code Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_for_task(pipeline, task_description, n_examples=3, \n",
    "                           generation_model=\"x-ai/grok-4-fast:free\", verbose=True):\n",
    "    \"\"\"\n",
    "    Generate code for a given task using the RAG pipeline.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: Dictionary containing pipeline components from setup_rag_pipeline\n",
    "        task_description: Natural language description of the coding task\n",
    "        n_examples: Number of similar examples to retrieve\n",
    "        generation_model: Model to use for code generation\n",
    "        verbose: Whether to print retrieval information\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing generated code and retrieved examples\n",
    "    \"\"\"\n",
    "    # Retrieve similar examples (higher similarity = more similar)\n",
    "    similarities, indices = search_similar(\n",
    "        task_description,\n",
    "        pipeline['embedding_model'],\n",
    "        pipeline['faiss_index'],\n",
    "        k=n_examples\n",
    "    )\n",
    "    \n",
    "    retrieved_examples = [pipeline['examples'][idx] for idx in indices]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"📚 Retrieved {len(retrieved_examples)} similar examples:\")\n",
    "        print(\"=\"*80)\n",
    "        for i, (ex, sim) in enumerate(zip(retrieved_examples, similarities), 1):\n",
    "            print(f\"{i}. {ex['task_id']} (similarity: {sim:.4f})\")\n",
    "            print(f\"   {ex['prompt'][:100]}...\")\n",
    "            print()\n",
    "    \n",
    "    # Generate code\n",
    "    generated_code = generate_code(\n",
    "        task_description,\n",
    "        retrieved_examples,\n",
    "        pipeline['api_key'],\n",
    "        model=generation_model\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"task_description\": task_description,\n",
    "        \"generated_code\": generated_code,\n",
    "        \"retrieved_examples\": [\n",
    "            {\n",
    "                \"task_id\": ex['task_id'],\n",
    "                \"prompt\": ex['prompt'],\n",
    "                \"canonical_solution\": ex['canonical_solution'],\n",
    "                \"similarity\": float(sim)\n",
    "            }\n",
    "            for ex, sim in zip(retrieved_examples, similarities)\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    \"\"\"Pretty print the generation result.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📝 TASK DESCRIPTION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result[\"task_description\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"💻 GENERATED CODE:\")\n",
    "    print(\"=\"*80)\n",
    "    print(result[\"generated_code\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📚 RETRIEVED EXAMPLES:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, ex in enumerate(result[\"retrieved_examples\"], 1):\n",
    "        print(f\"\\n{i}. {ex['task_id']} (cosine similarity: {ex['similarity']:.4f})\")\n",
    "        print(f\"   {ex['prompt'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Initialize the Pipeline\n",
    "\n",
    "Run this cell to set up the entire RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🚀 Setting up RAG Pipeline with Normalized FAISS\n",
      "================================================================================\n",
      "\n",
      "Loading HumanEval dataset...\n",
      "✓ Loaded 164 examples\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Creating embeddings for 164 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd00b758f93f482f99c3590ee5ae5e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created embeddings with shape: (164, 384)\n",
      "Building normalized FAISS index with Inner Product...\n",
      "✓ Normalized 164 vectors\n",
      "✓ FAISS index built with 164 vectors\n",
      "  Using: IndexIDMap(IndexFlatIP) for cosine similarity\n",
      "\n",
      "✓ Pipeline setup complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = setup_rag_pipeline(\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    "    embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Example 1: Calculate Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Retrieved 3 similar examples:\n",
      "================================================================================\n",
      "1. HumanEval/47 (similarity: 0.8026)\n",
      "   \n",
      "\n",
      "def median(l: list):\n",
      "    \"\"\"Return median of elements in the list l.\n",
      "    >>> median([3, 1, 2, 4, 5...\n",
      "\n",
      "2. HumanEval/4 (similarity: 0.6628)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a ...\n",
      "\n",
      "3. HumanEval/21 (similarity: 0.5341)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def rescale_to_unit(numbers: List[float]) -> List[float]:\n",
      "    \"\"\" Given li...\n",
      "\n",
      "🤖 Generating code...\n",
      "\n",
      "================================================================================\n",
      "📝 TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    \"\"\" Calculate the median of a list of numbers.\n",
      "    >>> calculate_median([3, 1, 2, 4, 5])\n",
      "    3.0\n",
      "    >>> calculate_median([1, 2, 3, 4])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "💻 GENERATED CODE:\n",
      "================================================================================\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def calculate_median(numbers: List[float]) -> float:\n",
      "    \"\"\" Calculate the median of a list of numbers.\n",
      "    >>> calculate_median([3, 1, 2, 4, 5])\n",
      "    3.0\n",
      "    >>> calculate_median([1, 2, 3, 4])\n",
      "    2.5\n",
      "    \"\"\"\n",
      "    numbers = sorted(numbers)\n",
      "    n = len(numbers)\n",
      "    if n % 2 == 1:\n",
      "        return float(numbers[n // 2])\n",
      "    else:\n",
      "        mid1 = numbers[n // 2 - 1]\n",
      "        mid2 = numbers[n // 2]\n",
      "        return (mid1 + mid2) / 2.0\n",
      "\n",
      "================================================================================\n",
      "📚 RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/47 (cosine similarity: 0.8026)\n",
      "   \n",
      "\n",
      "def median(l: list):\n",
      "    \"\"\"Return median of elements in the list l.\n",
      "    >>> median([3, 1, 2, 4, 5])\n",
      "    3\n",
      "    >>> median([-10, 4, 6, 1000, 10, 20])...\n",
      "\n",
      "2. HumanEval/4 (cosine similarity: 0.6628)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolu...\n",
      "\n",
      "3. HumanEval/21 (cosine similarity: 0.5341)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def rescale_to_unit(numbers: List[float]) -> List[float]:\n",
      "    \"\"\" Given list of numbers (of at least two elements), apply a ...\n"
     ]
    }
   ],
   "source": [
    "task1 = \"\"\"\n",
    "def calculate_median(numbers: List[float]) -> float:\n",
    "    \\\"\\\"\\\" Calculate the median of a list of numbers.\n",
    "    >>> calculate_median([3, 1, 2, 4, 5])\n",
    "    3.0\n",
    "    >>> calculate_median([1, 2, 3, 4])\n",
    "    2.5\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result1 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task1,\n",
    "    n_examples=3,\n",
    "    generation_model=\"x-ai/grok-4-fast:free\"\n",
    ")\n",
    "\n",
    "print_result(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Example 2: Palindrome Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Retrieved 3 similar examples:\n",
      "================================================================================\n",
      "1. HumanEval/48 (similarity: 0.8870)\n",
      "   \n",
      "\n",
      "def is_palindrome(text: str):\n",
      "    \"\"\"\n",
      "    Checks if given string is a palindrome\n",
      "    >>> is_palind...\n",
      "\n",
      "2. HumanEval/10 (similarity: 0.7355)\n",
      "   \n",
      "\n",
      "def is_palindrome(string: str) -> bool:\n",
      "    \"\"\" Test if given string is a palindrome \"\"\"\n",
      "    retur...\n",
      "\n",
      "3. HumanEval/112 (similarity: 0.6228)\n",
      "   \n",
      "def reverse_delete(s,c):\n",
      "    \"\"\"Task\n",
      "    We are given two strings s and c, you have to deleted all ...\n",
      "\n",
      "🤖 Generating code...\n",
      "\n",
      "================================================================================\n",
      "📝 TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def is_palindrome(s: str) -> bool:\n",
      "    \"\"\" Check if a string is a palindrome (ignoring spaces and case).\n",
      "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
      "    True\n",
      "    >>> is_palindrome(\"hello\")\n",
      "    False\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "💻 GENERATED CODE:\n",
      "================================================================================\n",
      "def is_palindrome(s: str) -> bool:\n",
      "    \"\"\" Check if a string is a palindrome (ignoring spaces and case).\n",
      "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
      "    True\n",
      "    >>> is_palindrome(\"hello\")\n",
      "    False\n",
      "    \"\"\"\n",
      "    cleaned = ''.join(c.lower() for c in s if not c.isspace())\n",
      "    return cleaned == cleaned[::-1]\n",
      "\n",
      "================================================================================\n",
      "📚 RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/48 (cosine similarity: 0.8870)\n",
      "   \n",
      "\n",
      "def is_palindrome(text: str):\n",
      "    \"\"\"\n",
      "    Checks if given string is a palindrome\n",
      "    >>> is_palindrome('')\n",
      "    True\n",
      "    >>> is_palindrome('aba')\n",
      "   ...\n",
      "\n",
      "2. HumanEval/10 (cosine similarity: 0.7355)\n",
      "   \n",
      "\n",
      "def is_palindrome(string: str) -> bool:\n",
      "    \"\"\" Test if given string is a palindrome \"\"\"\n",
      "    return string == string[::-1]\n",
      "\n",
      "\n",
      "def make_palindrome(str...\n",
      "\n",
      "3. HumanEval/112 (cosine similarity: 0.6228)\n",
      "   \n",
      "def reverse_delete(s,c):\n",
      "    \"\"\"Task\n",
      "    We are given two strings s and c, you have to deleted all the characters in s that are equal to any characte...\n"
     ]
    }
   ],
   "source": [
    "task2 = \"\"\"\n",
    "def is_palindrome(s: str) -> bool:\n",
    "    \\\"\\\"\\\" Check if a string is a palindrome (ignoring spaces and case).\n",
    "    >>> is_palindrome(\"A man a plan a canal Panama\")\n",
    "    True\n",
    "    >>> is_palindrome(\"hello\")\n",
    "    False\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result2 = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=task2,\n",
    "    n_examples=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print_result(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Example 3: Custom Task\n",
    "\n",
    "Try your own coding task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Retrieved 3 similar examples:\n",
      "================================================================================\n",
      "1. HumanEval/26 (similarity: 0.7875)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def remove_duplicates(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a lis...\n",
      "\n",
      "2. HumanEval/34 (similarity: 0.6059)\n",
      "   \n",
      "\n",
      "def unique(l: list):\n",
      "    \"\"\"Return sorted unique elements in a list\n",
      "    >>> unique([5, 3, 5, 2, 3,...\n",
      "\n",
      "3. HumanEval/104 (similarity: 0.5869)\n",
      "   \n",
      "def unique_digits(x):\n",
      "    \"\"\"Given a list of positive integers x. return a sorted list of all \n",
      "    ...\n",
      "\n",
      "🤖 Generating code...\n",
      "\n",
      "================================================================================\n",
      "📝 TASK DESCRIPTION:\n",
      "================================================================================\n",
      "\n",
      "def find_duplicates(nums: List[int]) -> List[int]:\n",
      "    \"\"\" Find all duplicate numbers in a list.\n",
      "    >>> find_duplicates([1, 2, 3, 2, 4, 3])\n",
      "    [2, 3]\n",
      "    >>> find_duplicates([1, 2, 3, 4])\n",
      "    []\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "================================================================================\n",
      "💻 GENERATED CODE:\n",
      "================================================================================\n",
      "from collections import Counter\n",
      "\n",
      "c = Counter(nums)\n",
      "added = set()\n",
      "result = []\n",
      "for n in nums:\n",
      "    if c[n] > 1 and n not in added:\n",
      "        result.append(n)\n",
      "        added.add(n)\n",
      "return result\n",
      "\n",
      "================================================================================\n",
      "📚 RETRIEVED EXAMPLES:\n",
      "================================================================================\n",
      "\n",
      "1. HumanEval/26 (cosine similarity: 0.7875)\n",
      "   from typing import List\n",
      "\n",
      "\n",
      "def remove_duplicates(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a list of integers, remove all elements that occur more...\n",
      "\n",
      "2. HumanEval/34 (cosine similarity: 0.6059)\n",
      "   \n",
      "\n",
      "def unique(l: list):\n",
      "    \"\"\"Return sorted unique elements in a list\n",
      "    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n",
      "    [0, 2, 3, 5, 9, 123]\n",
      "    \"\"\"\n",
      "...\n",
      "\n",
      "3. HumanEval/104 (cosine similarity: 0.5869)\n",
      "   \n",
      "def unique_digits(x):\n",
      "    \"\"\"Given a list of positive integers x. return a sorted list of all \n",
      "    elements that hasn't any even digit.\n",
      "\n",
      "    Note: Re...\n"
     ]
    }
   ],
   "source": [
    "# Define your own task here\n",
    "custom_task = \"\"\"\n",
    "def find_duplicates(nums: List[int]) -> List[int]:\n",
    "    \\\"\\\"\\\" Find all duplicate numbers in a list.\n",
    "    >>> find_duplicates([1, 2, 3, 2, 4, 3])\n",
    "    [2, 3]\n",
    "    >>> find_duplicates([1, 2, 3, 4])\n",
    "    []\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "result_custom = generate_code_for_task(\n",
    "    pipeline=pipeline,\n",
    "    task_description=custom_task,\n",
    "    n_examples=3\n",
    ")\n",
    "\n",
    "print_result(result_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Test Generated Code\n",
    "\n",
    "You can test if the generated code is valid Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Valid Python code generated!\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def validate_code(code: str) -> bool:\n",
    "    \"\"\"Check if generated code is valid Python.\"\"\"\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        return True\n",
    "    except SyntaxError as e:\n",
    "        print(f\"Syntax Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test the generated code\n",
    "if validate_code(result1[\"generated_code\"]):\n",
    "    print(\"✅ Valid Python code generated!\")\n",
    "else:\n",
    "    print(\"❌ Syntax error in generated code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Save/Load FAISS Index (Optional)\n",
    "\n",
    "Save the index to disk for faster future runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Index saved to humaneval_faiss_index.bin\n"
     ]
    }
   ],
   "source": [
    "# Save index\n",
    "faiss.write_index(pipeline['faiss_index'], \"humaneval_faiss_index.bin\")\n",
    "print(\"✓ Index saved to humaneval_faiss_index.bin\")\n",
    "\n",
    "# To load later:\n",
    "# loaded_index = faiss.read_index(\"humaneval_faiss_index.bin\")\n",
    "# pipeline['faiss_index'] = loaded_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Batch Processing Multiple Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing Task 1/3\n",
      "================================================================================\n",
      "🤖 Generating code...\n",
      "\n",
      "✓ Generated code for: def reverse_string(s: str) -> str: # Reverse a str...\n",
      "def reverse_string(s: str) -> str:\n",
      "    \"\"\"Reverse a string.\n",
      "    >>> reverse_string('hello')\n",
      "    'olleh'\n",
      "    \"\"\"\n",
      "    return s[::-1]\n",
      "\n",
      "================================================================================\n",
      "Processing Task 2/3\n",
      "================================================================================\n",
      "🤖 Generating code...\n",
      "\n",
      "✓ Generated code for: def count_vowels(text: str) -> int: # Count vowels...\n",
      "def count_vowels(text: str) -> int:\n",
      "    vowels = \"aeiouAEIOU\"\n",
      "    return sum(c in vowels for c in text)\n",
      "\n",
      "================================================================================\n",
      "Processing Task 3/3\n",
      "================================================================================\n",
      "🤖 Generating code...\n",
      "\n",
      "✓ Generated code for: def is_prime(n: int) -> bool: # Check if number is...\n",
      "import math\n",
      "\n",
      "def is_prime(n: int) -> bool:\n",
      "    \"\"\"Return True if a given number is prime, and False otherwise.\"\"\"\n",
      "    if n < 2:\n",
      "        return False\n",
      "    for k in range(2, int(math.sqrt(n)) + 1):\n",
      "        if n % k == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "✅ Completed 3 tasks!\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    \"def reverse_string(s: str) -> str: # Reverse a string\",\n",
    "    \"def count_vowels(text: str) -> int: # Count vowels in text\",\n",
    "    \"def is_prime(n: int) -> bool: # Check if number is prime\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i, task in enumerate(tasks, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Task {i}/{len(tasks)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    result = generate_code_for_task(\n",
    "        pipeline=pipeline,\n",
    "        task_description=task,\n",
    "        n_examples=2,\n",
    "        verbose=False\n",
    "    )\n",
    "    results.append(result)\n",
    "    print(f\"\\n✓ Generated code for: {task[:50]}...\")\n",
    "    print(result[\"generated_code\"])\n",
    "\n",
    "print(f\"\\n✅ Completed {len(results)} tasks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Summary\n",
    "\n",
    "You've successfully created a RAG code generation system that:\n",
    "- ✅ Loads the HumanEval dataset\n",
    "- ✅ Creates embeddings using Sentence Transformers\n",
    "- ✅ Builds a FAISS vector index for fast retrieval\n",
    "- ✅ Retrieves similar code examples\n",
    "- ✅ Generates new code using open-source LLMs via OpenRouter\n",
    "\n",
    "### Next Steps:\n",
    "1. Try different embedding models for better retrieval\n",
    "2. Experiment with various generation models\n",
    "3. Adjust `n_examples` based on task complexity\n",
    "4. Save the index for faster future runs\n",
    "5. Implement evaluation metrics for generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ede457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Evaluation Functions ====================\n",
    "\n",
    "def evaluate_faiss_accuracy(index, embeddings, ids, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval accuracy for FAISS index using self-retrieval.\n",
    "    Each prompt should retrieve itself as the nearest neighbor.\n",
    "    \n",
    "    Args:\n",
    "        index: FAISS index\n",
    "        embeddings: np.ndarray of normalized embeddings\n",
    "        ids: list of task_ids in the same order\n",
    "        k: number of neighbors to check\n",
    "    \n",
    "    Returns:\n",
    "        dict with accuracy@1, accuracy@k, and MRR\n",
    "    \"\"\"\n",
    "    total = len(ids)\n",
    "    correct_at_1 = 0\n",
    "    correct_at_k = 0\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        query = np.expand_dims(emb, axis=0).astype(\"float32\")\n",
    "        faiss.normalize_L2(query)\n",
    "        D, I = index.search(query, k)\n",
    "\n",
    "        retrieved_ids = [ids[j] for j in I[0] if j != -1]\n",
    "\n",
    "        # accuracy@1\n",
    "        if ids[i] == retrieved_ids[0]:\n",
    "            correct_at_1 += 1\n",
    "            reciprocal_ranks.append(1.0)\n",
    "        else:\n",
    "            # accuracy@k\n",
    "            if ids[i] in retrieved_ids:\n",
    "                correct_at_k += 1\n",
    "                rank = retrieved_ids.index(ids[i]) + 1\n",
    "                reciprocal_ranks.append(1.0 / rank)\n",
    "            else:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "\n",
    "    acc1 = correct_at_1 / total\n",
    "    acck = (correct_at_1 + correct_at_k) / total\n",
    "    mrr = sum(reciprocal_ranks) / total\n",
    "\n",
    "    return {\"accuracy@1\": acc1, f\"accuracy@{k}\": acck, \"MRR\": mrr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 FAISS Retrieval Evaluation:\n",
      "  accuracy@1: 1.0000\n",
      "  accuracy@5: 1.0000\n",
      "  MRR: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate FAISS index quality\n",
    "embeddings = pipeline['embedding_model'].encode(\n",
    "    extract_prompts(pipeline['examples'])\n",
    ").astype(\"float32\")\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "results = evaluate_faiss_accuracy(\n",
    "    pipeline['faiss_index'],\n",
    "    embeddings,\n",
    "    [ex['task_id'] for ex in pipeline['examples']],\n",
    "    k=5\n",
    ")\n",
    "print(\"\\n📊 FAISS Retrieval Evaluation:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
